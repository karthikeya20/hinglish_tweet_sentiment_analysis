{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SENTIMENT ANALYSIS</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the final translated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "train_tweets=[]\n",
    "train_tags=[]\n",
    "test_tweets=[]\n",
    "test_tags=[]\n",
    "d={'negative':0,'neutral':1,'positive':2}\n",
    "with open('./help_files/train_final_trans.txt','r') as f:\n",
    "    k = f.readlines()\n",
    "    for i in k:\n",
    "        l=i.strip().split()\n",
    "        train_tweets.append(' '.join(l[1:-1]))\n",
    "        train_tags.append(d[l[-1]])\n",
    "with open('./help_files/test_final_trans.txt','r') as f:\n",
    "    k = f.readlines()\n",
    "    for i in k:\n",
    "        l=i.strip().split()\n",
    "        test_tweets.append(' '.join(l[1:-1]))\n",
    "        test_tags.append(d[l[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "mapping=['__label__NEGATIVE','__label__NEUTRAL','__label__POSITIVE']\n",
    "def filter(tweets,tweet_tags):\n",
    "    out_tweets=[]\n",
    "    for i in range(len(tweets)):\n",
    "        tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweets[i]).split())\n",
    "        tweet = tweet.lower()\n",
    "        if 'ø' in tweet or  'Ø' in tweet:\n",
    "            tweet=tweet\n",
    "        else:\n",
    "            tweet = tweet.encode('ascii', 'ignore')\n",
    "            tweet = tweet.decode(\"utf-8\")\n",
    "        out_tweets.append([mapping[tweet_tags[i]],str(tweet)])\n",
    "    return(out_tweets)\n",
    "train=filter(train_tweets,train_tags)\n",
    "test=filter(test_tweets,test_tags)\n",
    "with open('./help_files/train.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(train)\n",
    "with open('./help_files/test.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(test)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after translating to english and preprocessing text this is fasttext by facebook research for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fasttext as fastText\n",
    "#hyper_params= {\"lr\": 0.2,\"epoch\": 2,\"wordNgrams\": 2,\"dim\": 30,}     \n",
    "hyper_params= {\"lr\": 0.4,\"epoch\": 2,\"wordNgrams\": 2,\"dim\": 18,}     \n",
    "\n",
    "model = fastText.train_supervised(input='./help_files/actual_train.txt', **hyper_params)\n",
    "test=test_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for saving data and calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[['tweet','actual','predicted']]\n",
    "for i in range(len(test)):\n",
    "    l.append([test[i],test_tags[i],model.predict(test[i])])\n",
    "with open('./help_files/output.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(l)\n",
    "import csv\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "total=0\n",
    "correct=0\n",
    "wrong=0\n",
    "d={'__label__NEUTRAL':1,'__label__NEGATIVE':0,'__label__POSITIVE':2}\n",
    "c=0\n",
    "with open('./help_files/output.csv','rt')as f:\n",
    "\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        c+=1\n",
    "\n",
    "        if c>1:\n",
    "            k=row[2]\n",
    "            st=k.find('_')\n",
    "            end=k.find(',')\n",
    "            total+=1\n",
    "            y_pred.append(int(d[row[2][st:end-1]]))\n",
    "            y_true.append(int(row[1]))\n",
    "            if int(d[row[2][st:end-1]])==int(row[1]):\n",
    "\n",
    "                correct+=1\n",
    "            else:\n",
    "                wrong+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE METRICS ARE AS FOLLOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  0.566916488222698\n",
      "\n",
      "\n",
      "**************************************************\n",
      "classsification report\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.57       532\n",
      "           1       0.54      0.54      0.54       754\n",
      "           2       0.60      0.60      0.60       582\n",
      "\n",
      "    accuracy                           0.57      1868\n",
      "   macro avg       0.57      0.57      0.57      1868\n",
      "weighted avg       0.57      0.57      0.57      1868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "prec=classification_report(y_true,y_pred)\n",
    "print('accuracy is: ',acc)\n",
    "print('\\n')\n",
    "print('*'*50)\n",
    "\n",
    "print('classsification report')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
